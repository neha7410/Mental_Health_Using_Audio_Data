{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEwcnJkaRyKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing images\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models,preprocessing,regularizers,callbacks\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "datagen = preprocessing.image.ImageDataGenerator(rescale=1/255)# normalisation\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        'final_image_data/train',\n",
        "        batch_size=10,\n",
        "        target_size=(512,512),\n",
        "        class_mode='binary')\n",
        "val_generator = datagen.flow_from_directory(\n",
        "        'final_image_data/val',\n",
        "        color_mode='rgb',\n",
        "        target_size=(512,512),\n",
        "        class_mode='binary')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLn8a1D2yjMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (5,5), activation='relu', input_shape=(512, 512, 3)))\n",
        "model.add(layers.MaxPooling2D((4, 4), strides=4))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(layers.MaxPooling2D((1, 3), strides=(1,3)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='linear',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(layers.Dropout(0.6))\n",
        "model.add(layers.Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model.add(layers.Dropout(0.8))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy',\n",
        "                       tf.keras.metrics.TrueNegatives(),\n",
        "                       tf.keras.metrics.TruePositives(),\n",
        "                       tf.keras.metrics.FalseNegatives(),\n",
        "                       tf.keras.metrics.FalsePositives()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxWqf07xjrp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fitiing\n",
        "history=model.fit_generator(train_generator,epochs=50,validation_data=val_generator,shuffle=True,\n",
        "                            callbacks=[callbacks.EarlyStopping(monitor='val_acc', patience=5,restore_best_weights=True)])\n",
        "# using early stopping method to train the model to achieve maximum accuracy\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTU-qpGgLUqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing \n",
        "loss,accuracy,tn,tp,fn,fp=model.evaluate_generator(val_generator)\n",
        "print(accuracy,tn,tp,fn,fp)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}